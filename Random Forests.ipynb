{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section I will fit an initial out-of-the-box Random Forest and then optimise the hyper-parameters to try and improve my model's accuracy.\n",
    "\n",
    "A Random Forest is an example of an ensemble classifier that aggregates multiple Decision Trees and averages over them in an effort to reduce over-fitting and to improve the accuracy of the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I need to import my TF-IDF vectorised data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF-IDF data\n",
    "X_train_head = pd.read_csv('data/X_train_head.csv')\n",
    "\n",
    "X_test_head = pd.read_csv('data/X_test_head.csv')\n",
    "\n",
    "y_train_head = pd.read_csv('data/y_train_head.csv')\n",
    "\n",
    "y_test_head = pd.read_csv('data/y_test_head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8258, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_head.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Idiot/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6667473964640349\n",
      "Test Accuracy: 0.6334140435835351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train_head, y_train_head)\n",
    "\n",
    "training_score = random_forest.score(X_train_head, y_train_head)\n",
    "test_score = random_forest.score(X_test_head, y_test_head)\n",
    " \n",
    "print(f'Training Accuracy: {training_score}')\n",
    "print(f'Test Accuracy: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our out-of-the-box Random Forest Classifier has managed to do a little better than our optimised Logistic Regression Classifier using all the features. \n",
    "\n",
    "It improved the training accuracy by 3.8% and the test accuracy by 0.7%. Let's see how optimising this model is able to improve our accuracy scores.\n",
    "\n",
    "To optimise my model I will use GridSearchCV with a 5-fold cross-validation. The hyper-parameters I will be optimising over are:\n",
    "\n",
    "n_estimators, criterion, max_depth, min_samples_split, min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Idiot/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [10, 25, 50, 75, 100],\n",
    "    'max_depth': np.arange(1,20),\n",
    "    'min_samples_split': np.arange(2,10),\n",
    "    'min_samples_leaf': np.arange(1,10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "gridsearch = GridSearchCV(RandomForestClassifier(), params, cv=5, n_jobs=-1)\n",
    "\n",
    "gridsearch_results = gridsearch.fit(X_train_head, y_train_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 18,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 25}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gridsearch_results.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6290872213333177"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_results.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Idiot/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6415596996851538\n",
      "Test Accuracy: 0.625181598062954\n"
     ]
    }
   ],
   "source": [
    "# Build a Random Forest with the optimised parameters\n",
    "random_forest_opt = RandomForestClassifier(n_estimators=best_params[\"n_estimators\"],\n",
    "                                           max_depth=best_params[\"max_depth\"],\n",
    "                                           min_samples_split=best_params[\"min_samples_split\"],\n",
    "                                           min_samples_leaf=best_params[\"min_samples_leaf\"],\n",
    "                                           criterion=best_params[\"criterion\"]                                  \n",
    "                                          )\n",
    "random_forest_opt.fit(X_train_head, y_train_head)\n",
    "\n",
    "training_score = random_forest_opt.score(X_train_head, y_train_head)\n",
    "test_score = random_forest_opt.score(X_test_head, y_test_head)\n",
    " \n",
    "print(f'Training Accuracy: {training_score}')\n",
    "print(f'Test Accuracy: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimising over all the parameters did not help me improve my test accuracy over the out-of-the-box model. So using the Random Forest, my best accuracy is 63.5%. \n",
    "\n",
    "Let's take a look at the feature importance from the original out-of-the-box Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top features: Index(['h_obama', 'h_gop', 'h_debate', 'h_hillary', 'h_10', 'h_trump',\n",
      "       'h_week', 'h_clinton', 'h_say', 'h_video'],\n",
      "      dtype='object')\n",
      "Feature values: [0.06820744 0.0648731  0.05471714 0.05193111 0.04784863 0.04256605\n",
      " 0.03508505 0.03475165 0.03247237 0.02945785]\n"
     ]
    }
   ],
   "source": [
    "# Sort the features by indice in order of most important to least important\n",
    "features = random_forest.feature_importances_\n",
    "sorted_indices = np.argsort(-1*features)\n",
    "sorted_features = np.sort(features)[::-1]\n",
    "\n",
    "# Pull out the top 5 features and pick out the corresponding columns\n",
    "top_5 = sorted_indices[0:10]\n",
    "columns = X_train_head.columns[top_5]\n",
    "print(f'Top features: {columns}')\n",
    "print(f'Feature values: {sorted_features[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Top 10 features by importance from the out-of-the box Random Forest are a mix of Democrat and Republican sentiment, with people/figures taking the focus: Obama, Hillary Clinton and Trump."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was optimistic that an optimised Random Forest would provide a bit more improvement over the Logistic Regression, but not to be. Let's see what some Recurrent Neural Networks will be able to achieve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
